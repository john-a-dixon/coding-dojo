{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ensemble Trees Exercise**\n",
    "\n",
    "_John Andrew Dixon_\n",
    "\n",
    "---\n",
    "\n",
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 7 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   NOX      506 non-null    float64\n",
      " 2   RM       506 non-null    float64\n",
      " 3   AGE      506 non-null    float64\n",
      " 4   PTRATIO  506 non-null    float64\n",
      " 5   LSTAT    506 non-null    float64\n",
      " 6   PRICE    506 non-null    float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 27.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Remote URL to the data\n",
    "url =\"https://docs.google.com/spreadsheets/d/e/2PACX-1vSQc1CsJ25nPMJcuJD04csFCysrzuInd_IQ_drLza49m_3R4MllPcuhduu4GozMJun3MgUJkGl0cw-d/pub?output=csv\"\n",
    "# Load and verify data\n",
    "df = pd.read_csv(url)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for evaluating regression R^2 scores\n",
    "def regression_r2(regression, tts_tuple, verbose=False):\n",
    "    \"\"\"Function for evaluating a model's R^2 scores\"\"\"\n",
    "    training_r2 = regression.score(tts_tuple[0], tts_tuple[2])\n",
    "    testing_r2 = regression.score(tts_tuple[1], tts_tuple[3])\n",
    "    if verbose:\n",
    "        print(\"Training R-squared:\", training_r2)\n",
    "        print(\"Testing R-squared:\", testing_r2)\n",
    "\n",
    "    return training_r2, testing_r2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Tasks**\n",
    "\n",
    "### **Try a Decision Tree, Bagged Tree, and Random Forest.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix and target vector\n",
    "X = df.drop(columns=\"PRICE\")\n",
    "y = df[\"PRICE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring default trees and forest regressors into the mix\n",
    "dt_default = DecisionTreeRegressor(random_state=42)\n",
    "bt_default = BaggingRegressor(random_state=42)\n",
    "rf_default = RandomForestRegressor(random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tune each model to optimize performance on the test set.**\n",
    "- After using a loop to tune each model, remember to create the best version of the model using the best hyperparameter values for the model based on the metrics you generated in your loop. The metrics from this best version model are what you will compare to the metrics of the other best version models to determine the overall best model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluate your best model using multiple regression metrics.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Explain in a text cell how your model will perform if deployed by referring to the metrics.  Ex. How close can your stakeholders expect its predictions to be to the true value?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
